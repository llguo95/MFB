{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3fc3c5-6a44-48b2-923d-61ee36cef912",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 1. Introduction\n",
    "\n",
    "This notebook presents `MFB` (Multi-Fidelity Benchmark). \n",
    "\n",
    "It is a set of scripts, written to facilitate multi-output or multi-fidelity regression and Bayesian optimization with Gaussian processes. \n",
    "\n",
    "It is built from elements of the `GPy`, `emukit` and `torch/gpytorch/botorch` packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728e418-5bbf-4c07-9c41-8ac8a07ce2d2",
   "metadata": {},
   "source": [
    "## 1.1 Setup\n",
    "\n",
    "In case you would like to use a new Python environment for this project: create a Python 3.7 environment, for example by running `conda create env -n MFBenv python=3.7` if you use conda.\n",
    "\n",
    "Populate the environment with the following standard libraries (if you use `pip`):"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fb1b0e2-ba0a-4ee3-add9-1c62d9320588",
   "metadata": {},
   "source": [
    "pip install numpy matplotlib torch gpytorch botorch emukit pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2249400-cdca-4c1e-97bb-d432d1cd4c03",
   "metadata": {},
   "source": [
    "You will also need some libraries that are not registered as PyPI packages and therefore need to be collected and placed manually.\n",
    "These are:\n",
    "- `GPy` with cokg-d: https://github.com/taylanot/GPy\n",
    "- `pybenchfunction`, a repository of test functions: https://github.com/llguo95/Python_Benchmark_Test_Optimization_Function_Single_Objective\n",
    "\n",
    "It is recommended to place the directories at the same level as `MFB`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc67906-662a-495b-8147-5054a37ba2cf",
   "metadata": {},
   "source": [
    "Provide the relative path, i.e., relative to the path of this jupyter notebook, to where `pybenchfunction`, `GPy` with cokg-d and `MFB` are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2650188-36c1-42e9-8247-1186f60ba65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_lib_rel_path = '../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b12fb77-0fa7-41d1-a94c-935dd3ea2c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning in stationary: failed to import cython module: falling back to numpy\n",
      "warning in coregionalize: failed to import cython module: falling back to numpy\n",
      "warning in choleskies: failed to import cython module: falling back to numpy\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, custom_lib_rel_path + 'Python_Benchmark_Test_Optimization_Function_Single_Objective')\n",
    "import pybenchfunction\n",
    "\n",
    "sys.path.insert(0, custom_lib_rel_path + 'GPy')\n",
    "import GPy\n",
    "\n",
    "sys.path.insert(0, custom_lib_rel_path + 'MFB')\n",
    "from main import reg_main, bo_main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa1e32a-6667-4dd5-bf53-5f38530a5b0b",
   "metadata": {},
   "source": [
    "## 1.2 Structure of MFB\n",
    "The core structure is as follows:\n",
    "\n",
    "- `cokgj.py` contains a wrapper class that injects the cokg-j implementation of `emukit` into the `botorch` framework.\n",
    "- `main.py` contains functions to run the regression and optimization experiments. Read `MFB/readme.txt` for more information about the in- and outputs of these functions. It relies heavily on `pipeline.py`.\n",
    "- `MFproblem.py` contains the class for initializing 2-fidelity problem objects. This class has methods which can: \n",
    "    - generate DoE input data (both low and high fidelity) for the problem.\n",
    "    - initialize the appropriate GP model given `model_type`.\n",
    "    - initialize the appropriate acquisition function depending on fidelity type.\n",
    "    - optimize the acquisition function.\n",
    "- `objective_formatter.py`contains two classes:\n",
    "    - `botorch_TestFunction`, a wrapper class that injects a `pybench` `function` into the shape of a `botorch` `SyntheticTestFunction`.\n",
    "    - `AugmentedTestFunction`, a class that facilitates the augmentation of a `SyntheticTestFunction` object with a `LF` parameter, effectively creating a multi-fidelity objective out of a single-fidelity objective.\n",
    "- `pipeline.py` contains functions which, as a whole, construct and process the DoE data and return the relevant predictive means and variances. They are subdivided into `pretrainer`, `trainer` and `posttrainer` parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6975b8c-00f5-4410-9382-3e4784cddcd6",
   "metadata": {},
   "source": [
    "# 2. Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd4e87-e099-492f-a949-afa087f8c1dc",
   "metadata": {},
   "source": [
    "To get started, import the packages that are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "704b8658-c8d7-4be5-b711-773f94a625fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "from MFproblem import MFProblem\n",
    "from main import reg_main\n",
    "import pybenchfunction\n",
    "from objective_formatter import botorch_TestFunction, AugmentedTestFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697c40e3-3cd1-44d6-aae2-d9d03910b843",
   "metadata": {},
   "source": [
    "Next, define the parameters for which you want to run `reg_main` or `bo_main`. \n",
    "\n",
    "For example, to gather some statistics about the 1D Ackley function with 5 quasi-random initial DoE points and no assumed noise, you could define:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d8e6aa-534c-4d30-9306-cc4cd4134c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkwargs = {\n",
    "    \"dtype\": torch.double,\n",
    "    # \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"device\": torch.device(\"cpu\"),\n",
    "}\n",
    "\n",
    "f_class_list = pybenchfunction.get_functions(d=None, randomized_term=False)\n",
    "excluded_fs = ['Ackley N. 4', 'Brown', 'Langermann', 'Michalewicz', 'Rosenbrock', 'Shubert', 'Shubert N. 3', 'Shubert N. 4']\n",
    "fs = [f for f in f_class_list if f.name not in excluded_fs][:1]\n",
    "\n",
    "dim = 1\n",
    "noise_type = 'b'\n",
    "\n",
    "problem = [\n",
    "    MFProblem(\n",
    "        objective_function=AugmentedTestFunction(\n",
    "            botorch_TestFunction(\n",
    "                f(d=dim), negate=False, # Minimization\n",
    "            ), noise_type=noise_type,\n",
    "        ).to(**tkwargs)\n",
    "    )\n",
    "    for f in fs\n",
    "]\n",
    "\n",
    "model_type = ['sogpr']\n",
    "lf = [.5]\n",
    "n_reg = [5]\n",
    "n_reg_lf = [15]\n",
    "scramble = True\n",
    "noise_fix = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be47d41-5552-47da-8997-eefc21fe4a89",
   "metadata": {},
   "source": [
    "Then, you can run the function with these defined inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f2eb3f9-1552-420d-97e7-70f4559420e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "data, metadata = reg_main(\n",
    "    problem=problem,\n",
    "    model_type=model_type,\n",
    "    lf=lf,\n",
    "    n_reg=n_reg,\n",
    "    n_reg_lf=n_reg_lf,\n",
    "    scramble=scramble,\n",
    "    noise_fix=noise_fix,\n",
    "    noise_type=noise_type,\n",
    ")\n",
    "stop = time.time()\n",
    "print(stop - start)\n",
    "\n",
    "metadata['dim'] = dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ce7fe-440f-4e29-a237-bd1e53f28106",
   "metadata": {},
   "source": [
    "Uncomment these to save the statistics data (median RAAE, RMSTD and their IQR) with a timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4094344-5ca1-49c4-924f-b7c6d6642ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sogpr\n",
      "\n",
      "AugmentedAckley\n",
      "\n",
      "lf = 0.5\n",
      "n_reg = 5\n",
      "n_reg_lf_el = 15\n",
      "1.2348079681396484\n"
     ]
    }
   ],
   "source": [
    "# folder_path = 'notebooks_data/'\n",
    "# file_name = time.strftime(\"%Y%m%d%H%M%S\", time.gmtime())\n",
    "\n",
    "# open_file = open(folder_path + file_name + '.pkl', 'wb')\n",
    "# pickle.dump(data, open_file)\n",
    "# open_file.close()\n",
    "\n",
    "# open_file = open(folder_path + file_name + '_metadata.pkl', 'wb')\n",
    "# pickle.dump(metadata, open_file)\n",
    "# open_file.close()\n",
    "\n",
    "# with open(folder_path + file_name + '_metadata.txt', 'w') as data:\n",
    "#     data.write(str(metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fd6967-3ff6-471e-9c32-18bb7c4febbb",
   "metadata": {},
   "source": [
    "Then, to access the data, some postprocessing can be done. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63c4097-9d7f-4be8-bab1-fb8baf64f10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8032621441791635\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'notebooks_data/'\n",
    "\n",
    "file_names = [\n",
    "    '20220318084154'\n",
    "]\n",
    "\n",
    "f_class_list = pybenchfunction.get_functions(d=None, randomized_term=False)\n",
    "excluded_fs = ['Ackley N. 4', 'Brown', 'Langermann', 'Michalewicz', 'Rosenbrock', 'Shubert', 'Shubert N. 3', 'Shubert N. 4']\n",
    "fs = [f for f in f_class_list if f.name not in excluded_fs]\n",
    "# print([f.name for f in fs])\n",
    "\n",
    "model_types = ['cokg', 'cokg_dms', 'mtask']\n",
    "lfs = [0.1, 0.5, 0.9]\n",
    "\n",
    "mrmv = []\n",
    "metadata_mf = None\n",
    "for f_i, file_name in enumerate(file_names):\n",
    "    open_file = open(folder_path + file_name + '.pkl', 'rb')\n",
    "    data = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "\n",
    "    # print(data)\n",
    "\n",
    "    open_file = open(folder_path + file_name + '_metadata.pkl', 'rb')\n",
    "    metadata = pickle.load(open_file)\n",
    "    if f_i == 0:\n",
    "        metadata_mf = metadata\n",
    "    open_file.close()\n",
    "\n",
    "    # print(metadata['budget'])\n",
    "\n",
    "    # mrm = np.zeros((29, len(metadata['model_type'])))\n",
    "    mrm_model_type = {}\n",
    "    for model_no, model_type in enumerate(metadata['model_type']):\n",
    "        model_type_slice = data[model_type]\n",
    "\n",
    "        # print(model_type)\n",
    "        mrm_problem = {}\n",
    "        for problem_no, problem in enumerate(metadata['problem']):\n",
    "            if problem == 'AugmentedRidge' and metadata['dim'] == 1: continue\n",
    "            problem_slice = model_type_slice[problem]\n",
    "\n",
    "            # print(problem)\n",
    "\n",
    "            mrm_lf = {}\n",
    "            for lf in metadata['lf']:\n",
    "                lf_slice = problem_slice[lf]\n",
    "\n",
    "                # print(lf)\n",
    "\n",
    "                mrm_n_reg = []\n",
    "                for n_reg, n_reg_lf in zip(metadata['n_reg'], metadata['n_reg_lf']):\n",
    "                    n_reg_slice = lf_slice[(n_reg, n_reg_lf)]\n",
    "\n",
    "                    # print(n_reg_slice['RAAE_stats']['median'])\n",
    "                    # mrm[problem_no, model_no] = n_reg_slice['RAAE_stats']['median']\n",
    "                    mrm_n_reg.append(n_reg_slice['RAAE_stats']['median'])\n",
    "\n",
    "                    print(n_reg_slice['RAAE_stats']['median'])\n",
    "                mrm_lf[lf] = mrm_n_reg\n",
    "            mrm_problem[problem] = mrm_lf\n",
    "        mrm_model_type[model_type] = mrm_problem\n",
    "    mrmv.append(mrm_model_type)\n",
    "\n",
    "mrmv_mf, mrmv_sf = mrmv[:-1], mrmv[-1]\n",
    "\n",
    "# print(mrmv_mf)\n",
    "\n",
    "for mf_i, mf_scenario in enumerate(mrmv_mf):\n",
    "    df_data = {}\n",
    "    for model_type in mf_scenario:\n",
    "        fig, axs = plt.subplots(num=model_type + str(mf_i), ncols=1, nrows=3, sharex=True, sharey=True, figsize=(5, 8))\n",
    "        for lf_i, lf in enumerate(metadata_mf['lf']):\n",
    "            prob_stat_vec = []\n",
    "            for problem in metadata_mf['problem']:\n",
    "                if problem == 'AugmentedRidge' and metadata['dim'] == 1: continue\n",
    "                # mrmv_mf[model_type][problem][lf][0] = mrmv_sf['sogpr'][problem][0.1][0] / mrmv_mf[model_type][problem][lf][0]\n",
    "                # print(problem, mrmv_sf['sogpr'][problem][0.1][0], mrmv_mf[model_type][problem][lf][0])\n",
    "                lri = np.log10(mrmv_sf['sogpr'][problem][0.5][0] / mf_scenario[model_type][problem][lf][0])\n",
    "                # lri = np.log10(mrmv_sf['sogpr'][problem][0.1][0] / mf_scenario[model_type][problem][lf][0])\n",
    "                # lri = mrmv_sf['sogpr'][problem][0.1][0] / mrmv_mf[model_type][problem][lf][0]\n",
    "                prob_stat_vec.append(lri)\n",
    "            prop, nonprop = [], []\n",
    "            for stat_i, stat in enumerate(prob_stat_vec):\n",
    "                # print(fs[stat_i].name, fs[stat_i].convex)\n",
    "                (nonprop, prop)[fs[stat_i].multimodal is False].append(stat)\n",
    "\n",
    "            df_data[lf] = prob_stat_vec\n",
    "            print()\n",
    "            # print(model_type, lf, 10 ** np.median(prob_stat_vec), [10 ** np.quantile(prob_stat_vec, q=.25), 10 ** np.quantile(prob_stat_vec, q=.75)])\n",
    "            print(model_type, lf, np.median(prob_stat_vec), [np.quantile(prob_stat_vec, q=.25), np.quantile(prob_stat_vec, q=.75)])\n",
    "            print(model_type, lf, 'prop', np.median(prop), [np.quantile(prop, q=.25), np.quantile(prop, q=.75)])\n",
    "            print(model_type, lf, 'nonprop', np.median(nonprop), [np.quantile(nonprop, q=.25), np.quantile(nonprop, q=.75)])\n",
    "            ax = axs[lf_i]\n",
    "            # ax.hist(prob_stat_vec, bins=20, ec='k')\n",
    "            ax.hist((prop, nonprop), bins=20, ec='k', color=['g', 'r'], stacked=True)\n",
    "            ax.set_title('LF = ' + str(lf))\n",
    "            ax.axvline(x=0, color='k', linestyle='--', linewidth=3)\n",
    "            if lf_i == 2:\n",
    "                ax.set_xlabel('Relative improvement (orders of mag.)')\n",
    "            ax.set_ylabel('Frequency')\n",
    "            # ax.set_xscale('log')\n",
    "            # axs[lf_i].grid()\n",
    "        plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
